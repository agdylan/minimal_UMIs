{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Data Notebook\n",
    "\n",
    "This notebook performs the following steps:\n",
    "\n",
    "- **Process the `bam_file`** for each dataset to generate a **counts DataFrame**.\n",
    "- **Construct AnnData matrices** from the counts DataFrame, representing the naive counts for \\( u[k] \\) across all \\( k \\).\n",
    "- **Generate predicted counts** using:\n",
    "  - The **uniform model**\n",
    "  - The **non-uniform model**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Processing the Bam_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import sklearn\n",
    "import anndata as ad \n",
    "from tqdm import tqdm as tqdm\n",
    "import pysam\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam\n",
    "import pandas as pd\n",
    "\n",
    "# 1) INPUT: Path to the filtered BAM file (choose one dataset)\n",
    "filtered_bam_path = '/data/dagyeman/cellranger/bam_file_analysis/1k_PBMCs/filtered_1k_PBMCS_bam.bam'   # BAM file for 1k dataset\n",
    "# filtered_bam_path = '/data/dagyeman/cellranger/bam_file_analysis/10k_PBMCs/filtered_10k_PBMCS_bam.bam' # BAM file for 10k dataset\n",
    "# filtered_bam_path = '/data/dagyeman/cellranger/bam_file_analysis/500_PBMCs/filtered_500_PBMCS_bam.bam'    # BAM file for 500 dataset\n",
    "# filtered_bam_path = '/data/dagyeman/cellranger/bam_file_analysis/5k_PBMCs/filtered_5k_PBMCS_bam.bam'    # BAM file for 5k dataset\n",
    "\n",
    "# 2) data: list to hold extracted (barcode, gene, UMI) triplets\n",
    "data = []\n",
    "\n",
    "# 3) EXTRACT: Read BAM file and pull out barcode, gene, and UMI tags\n",
    "with pysam.AlignmentFile(filtered_bam_path, \"rb\") as bam_file:\n",
    "    for read in bam_file:\n",
    "        if read.has_tag('CB') and read.has_tag('GN') and read.has_tag('UB'):\n",
    "            barcode = read.get_tag('CB')  # string: cell barcode\n",
    "            gene = read.get_tag('GN')     # string: gene name\n",
    "            umi = read.get_tag('UB')      # string: unique molecular identifier\n",
    "            data.append([barcode, gene, umi])\n",
    "\n",
    "# 4) df: pandas DataFrame containing all reads with columns (barcode, gene, UMI)\n",
    "df = pd.DataFrame(data, columns=['barcode', 'gene', 'UMI'])\n",
    "print(\"First few raw rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# 5) CLEAN: Remove any rows where UMI contains ambiguous base 'N'\n",
    "df = df[~df['UMI'].str.contains('N')]\n",
    "\n",
    "# 6) deduplicated_df: DataFrame containing only unique (barcode, gene, UMI) combinations\n",
    "#    This is the deduplicated set of observed UMIs before truncating\n",
    "deduplicated_df = df.drop_duplicates(subset=['barcode', 'gene', 'UMI']).reset_index(drop=True)\n",
    "print(\"First few deduplicated rows:\")\n",
    "print(deduplicated_df.head())\n",
    "\n",
    "# 7) LOOP: For UMI lengths k = 1 to 12, compute number of unique UMIs per (barcode, gene)\n",
    "for k in range(1, 13):\n",
    "    deduplicated_df[f'UMI_{k}'] = deduplicated_df['UMI'].str[:k]  # first k bases\n",
    "    grouped_df = (\n",
    "        deduplicated_df.groupby(['barcode', 'gene'])[f'UMI_{k}']\n",
    "                       .nunique()\n",
    "                       .reset_index()\n",
    "                       .rename(columns={f'UMI_{k}': f'unique_UMI_count_{k}'})\n",
    "    )\n",
    "    print(f\"Unique UMI counts for UMI length {k}:\")\n",
    "    print(grouped_df.head())\n",
    "\n",
    "# 8) final_df: merged table with unique UMI counts for all lengths 1–12\n",
    "final_df = (\n",
    "    deduplicated_df.groupby(['barcode', 'gene'])\n",
    "                   .agg({f'UMI_{k}': 'nunique' for k in range(1, 13)})\n",
    "                   .reset_index()\n",
    ")\n",
    "final_df.columns = ['barcode', 'gene'] + [f'unique_UMI_count_{k}' for k in range(1, 13)]\n",
    "print(\"Final merged table:\")\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Adata Objects: Naive Method - created from final_df dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import anndata as ad\n",
    "\n",
    "# Dictionary to store the AnnData objects for each UMI length\n",
    "adata_dict = {}\n",
    "\n",
    "# Loop over UMI lengths from 1 to 12\n",
    "for k in range(1, 13):\n",
    "    # Extract the relevant columns for the current UMI length\n",
    "    # Contains: barcode, gene, and the deduplicated count for UMI length k\n",
    "    adata_matrix = final_df[['barcode', 'gene', f'unique_UMI_count_{k}']]\n",
    "\n",
    "    # Pivot the DataFrame:\n",
    "    # - Rows = barcodes (cells)\n",
    "    # - Columns = genes\n",
    "    # - Values = deduplicated UMI counts for the current UMI length\n",
    "    matrix_df = adata_matrix.pivot(\n",
    "        index='barcode',\n",
    "        columns='gene',\n",
    "        values=f'unique_UMI_count_{k}'\n",
    "    ).fillna(0)\n",
    "\n",
    "    # Create an AnnData object from the counts matrix\n",
    "    adata = ad.AnnData(X=matrix_df.values)\n",
    "\n",
    "    # Assign observation names (rows) to the barcodes\n",
    "    adata.obs_names = matrix_df.index\n",
    "\n",
    "    # Assign variable names (columns) to the gene names\n",
    "    adata.var_names = matrix_df.columns\n",
    "\n",
    "    # Store the AnnData object in the dictionary with the UMI length as the key\n",
    "    adata_dict[k] = adata\n",
    "\n",
    "# Example: View the AnnData object for UMI length 1\n",
    "print(adata_dict[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Adata Objects: Uniform Estimator "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mom_estimator_unif(y, K):\n",
    "    \"\"\"\n",
    "    Method-of-moments estimator for the uniform UMI model.\n",
    "\n",
    "    Given observed unique molecule counts y and total possible UMIs K,\n",
    "    estimates the underlying molecule counts n using the closed-form\n",
    "    inversion for the uniform collision model.\n",
    "\n",
    "    Works element-wise on scalars, vectors, or matrices.\n",
    "    Special handling is applied when y == K using a recursive relation.\n",
    "    \"\"\"\n",
    "    # Make sure y is a NumPy array\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Prepare an output array of floats with the same shape as y\n",
    "    result = np.empty_like(y, dtype=float)\n",
    "    \n",
    "    # Handle entries where y equals K\n",
    "    special_mask = (y == K)\n",
    "    if special_mask.any():\n",
    "        # Special case value from recursive formula\n",
    "        special_value = mom_estimator_unif(K - 1, K) + K\n",
    "        result[special_mask] = special_value\n",
    "    \n",
    "    # Handle all other entries\n",
    "    general_mask = ~special_mask\n",
    "    if general_mask.any():\n",
    "        denominator = np.log(1 - 1/K)\n",
    "        result[general_mask] = np.log(1 - y[general_mask] / K) / denominator\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating AnnData matrix for uniform estimator at length k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "\n",
    "filepath = \"/data/dagyeman/cellranger/bam_file_analysis/1k_PBMCs/ub_objects\" #1k\n",
    "# filepath = \"/data/dagyeman/cellranger/bam_file_analysis/10k_PBMCs/ub_objects\" #10k\n",
    "\n",
    "# Load naive AnnData counts (UMI lengths 1–12)\n",
    "adata_dict = {}\n",
    "for i in range(1, 13):\n",
    "    adata_dict[i] = sc.read_h5ad(f\"{filepath}/adata_matrices/adata_{i}.h5ad\")\n",
    "    \n",
    "\n",
    "# Build the predicted AnnData for a chosen UMI length k \n",
    "chosen_k = 6  # set this as needed\n",
    "\n",
    "adata = adata_dict[chosen_k]                 # naive counts AnnData for k\n",
    "\n",
    "# Dense matrix view of counts\n",
    "matrix = adata.X.toarray() if hasattr(adata.X, \"toarray\") else adata.X\n",
    "original_matrix = matrix.copy()              # keep a copy if you want to compare later\n",
    "\n",
    "# Predict counts with your estimator\n",
    "predicted_matrix = mom_estimator_unif(matrix, 4**chosen_k)\n",
    "# AnnData with predicted counts (cells x genes align with the naive object)\n",
    "predicted_adata = ad.AnnData(X=predicted_matrix)\n",
    "predicted_adata.obs_names = adata.obs_names\n",
    "predicted_adata.var_names = adata.var_names\n",
    "\n",
    "# Example check\n",
    "print(predicted_adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Adata Objects: Non-uniform Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import njit, prange\n",
    "\n",
    "@njit\n",
    "def interpolate(y, f_hat_values, n_values):\n",
    "    \"\"\"Interpolates the value of n for a given y using linear interpolation.\"\"\"\n",
    "    if y == 0:\n",
    "        return 0\n",
    "    # Find index in f_hat_values where y fits in\n",
    "    i = np.searchsorted(f_hat_values, y) - 1\n",
    "    # Clamp i so it’s never out of range\n",
    "    i = max(0, min(i, len(f_hat_values) - 2))\n",
    "\n",
    "    # Values for n and f at positions i and i+1\n",
    "    n_i = n_values[i]\n",
    "    n_ip1 = n_values[i + 1]\n",
    "    f_ni = f_hat_values[i]\n",
    "    f_nip1 = f_hat_values[i + 1]\n",
    "\n",
    "    # Linear interpolation\n",
    "    denom = f_nip1 - f_ni\n",
    "    return n_i + (y - f_ni) * (n_ip1 - n_i) / denom\n",
    "\n",
    "@njit(parallel=True)\n",
    "def interpolate_array(matrix_flat, f_hat_values, n_values, j):\n",
    "    \"\"\"Applies interpolation to each element in a flattened matrix.\"\"\"\n",
    "    result = np.empty_like(matrix_flat)\n",
    "    target_value = 4 ** j\n",
    "\n",
    "    for idx in prange(matrix_flat.size):\n",
    "        y = matrix_flat[idx]\n",
    "        if y == target_value:\n",
    "            # Special handling if value equals theoretical max\n",
    "            result[idx] = (\n",
    "                3 * interpolate(y - 1, f_hat_values, n_values)\n",
    "                - 3 * interpolate(y - 2, f_hat_values, n_values)\n",
    "                + interpolate(y - 3, f_hat_values, n_values)\n",
    "            )\n",
    "        else:\n",
    "            result[idx] = interpolate(y, f_hat_values, n_values)\n",
    "    return result\n",
    "\n",
    "def mom_estimator_nonunif(prob_arr, matrix, j, n_max=15000):\n",
    "    \"\"\"Returns the inverted matrix using the method of moments.\"\"\"\n",
    "    # Grid of possible n values\n",
    "    n_values = np.linspace(1, n_max, n_max)\n",
    "    # Expected f-hat for each n\n",
    "    f_hat_values = np.array([4**j - np.sum((1 - prob_arr)**n) for n in n_values])\n",
    "\n",
    "    # Flatten matrix for easier processing\n",
    "    matrix_flat = matrix.flatten().astype(np.float64)\n",
    "\n",
    "    # Check for out-of-bounds y values (allow exactly 4**j)\n",
    "    f_min, f_max = f_hat_values[0], f_hat_values[-1]\n",
    "    target = 4**j\n",
    "    mask = (matrix_flat > f_max) & (matrix_flat != target)\n",
    "    out_of_bounds = matrix_flat[mask]\n",
    "    if out_of_bounds.size > 0:\n",
    "        print(f\"Out-of-bounds y-values: {out_of_bounds}\")\n",
    "        raise ValueError(f\"Some y-values are outside interpolation range [{f_min}, {f_max}].\")\n",
    "        return \"Failed to invert matrix due to out-of-bounds values.\"\n",
    "\n",
    "    # Apply interpolation and reshape back to original\n",
    "    interpolated_flat = interpolate_array(matrix_flat, f_hat_values, n_values, j)\n",
    "    return interpolated_flat.reshape(matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating AnnData matrix for non-uniform estimator at length k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "\n",
    "filepath = \"/data/dagyeman/cellranger/bam_file_analysis/1k_PBMCs/ub_objects\" #1k\n",
    "# filepath = \"/data/dagyeman/cellranger/bam_file_analysis/10k_PBMCs/ub_objects\" #10k\n",
    "\n",
    "# Load naive AnnData counts (UMI lengths 1–12)\n",
    "adata_dict = {}\n",
    "for i in range(1, 13):\n",
    "    adata_dict[i] = sc.read_h5ad(f\"{filepath}/adata_matrices/adata_{i}.h5ad\")\n",
    "\n",
    "# Load non-uniform UMI probability distributions (UMI lengths 1–12)\n",
    "umi_prob_dict = {}\n",
    "for i in range(1, 13):\n",
    "    umi_prob_dict[i] = pd.read_csv(f\"/data/dagyeman/cellranger/umi_probs/umi_probs_{i}.csv\")\n",
    "\n",
    "# Build the predicted AnnData for a chosen UMI length k\n",
    "chosen_k = 6  # set this as needed\n",
    "\n",
    "adata = adata_dict[chosen_k]                 # naive counts AnnData for k\n",
    "umi_probs = umi_prob_dict[chosen_k]['prob']  # non-uniform probs for k\n",
    "\n",
    "# Dense matrix view of counts\n",
    "matrix = adata.X.toarray() if hasattr(adata.X, \"toarray\") else adata.X\n",
    "original_matrix = matrix.copy()              # keep a copy if you want to compare later\n",
    "\n",
    "# Predict counts with your estimator\n",
    "predicted_matrix = mom_estimator_nonunif(umi_probs.values, matrix, j=chosen_k)\n",
    "\n",
    "# AnnData with predicted counts (cells x genes align with the naive object)\n",
    "predicted_adata = ad.AnnData(X=predicted_matrix)\n",
    "predicted_adata.obs_names = adata.obs_names\n",
    "predicted_adata.var_names = adata.var_names\n",
    "\n",
    "# Example check\n",
    "print(predicted_adata)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
