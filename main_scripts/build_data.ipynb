{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Data Notebook\n",
    "\n",
    "This notebook performs the following steps:\n",
    "\n",
    "- **Process the `bam_file`** for each dataset to generate a **counts DataFrame**.\n",
    "- **Construct AnnData matrices** from the counts DataFrame, representing the naive counts for \\( u[k] \\) across all \\( k \\).\n",
    "- **Generate predicted counts** using:\n",
    "  - The **uniform model**\n",
    "  - The **non-uniform model**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Processing the Bam_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import sklearn\n",
    "import anndata as ad \n",
    "from tqdm import tqdm as tqdm\n",
    "import pysam\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few raw rows:\n",
      "              barcode         gene           UMI\n",
      "0  GTGACGTTCATGGTTG-1  MIR1302-2HG  GCCTTACGGCTC\n",
      "1  GGTATATTCGATGTCA-1  MIR1302-2HG  TACCGCCAACAG\n",
      "2  ATGTCCCCAGGCATTG-1  MIR1302-2HG  GTCGTCATTCGT\n",
      "3  GTCAATGTCGTCTCTG-1  MIR1302-2HG  AATATGAGTAGC\n",
      "4  ATCAAGCCAACCCTAC-1  MIR1302-2HG  CGAACGCACCCT\n",
      "First few deduplicated rows:\n",
      "              barcode         gene           UMI\n",
      "0  GTGACGTTCATGGTTG-1  MIR1302-2HG  GCCTTACGGCTC\n",
      "1  GGTATATTCGATGTCA-1  MIR1302-2HG  TACCGCCAACAG\n",
      "2  ATGTCCCCAGGCATTG-1  MIR1302-2HG  GTCGTCATTCGT\n",
      "3  GTCAATGTCGTCTCTG-1  MIR1302-2HG  AATATGAGTAGC\n",
      "4  ATCAAGCCAACCCTAC-1  MIR1302-2HG  CGAACGCACCCT\n",
      "Unique UMI counts for UMI length 1:\n",
      "              barcode   gene  unique_UMI_count_1\n",
      "0  AAACCAAAGGTGACGA-1  AAGAB                   1\n",
      "1  AAACCAAAGGTGACGA-1   AAK1                   4\n",
      "2  AAACCAAAGGTGACGA-1  AAMDC                   1\n",
      "3  AAACCAAAGGTGACGA-1   AAMP                   1\n",
      "4  AAACCAAAGGTGACGA-1   AAR2                   1\n",
      "Unique UMI counts for UMI length 2:\n",
      "              barcode   gene  unique_UMI_count_2\n",
      "0  AAACCAAAGGTGACGA-1  AAGAB                   1\n",
      "1  AAACCAAAGGTGACGA-1   AAK1                  10\n",
      "2  AAACCAAAGGTGACGA-1  AAMDC                   1\n",
      "3  AAACCAAAGGTGACGA-1   AAMP                   1\n",
      "4  AAACCAAAGGTGACGA-1   AAR2                   1\n",
      "Unique UMI counts for UMI length 3:\n",
      "              barcode   gene  unique_UMI_count_3\n",
      "0  AAACCAAAGGTGACGA-1  AAGAB                   1\n",
      "1  AAACCAAAGGTGACGA-1   AAK1                  15\n",
      "2  AAACCAAAGGTGACGA-1  AAMDC                   1\n",
      "3  AAACCAAAGGTGACGA-1   AAMP                   2\n",
      "4  AAACCAAAGGTGACGA-1   AAR2                   1\n",
      "Unique UMI counts for UMI length 4:\n",
      "              barcode   gene  unique_UMI_count_4\n",
      "0  AAACCAAAGGTGACGA-1  AAGAB                   1\n",
      "1  AAACCAAAGGTGACGA-1   AAK1                  15\n",
      "2  AAACCAAAGGTGACGA-1  AAMDC                   1\n",
      "3  AAACCAAAGGTGACGA-1   AAMP                   2\n",
      "4  AAACCAAAGGTGACGA-1   AAR2                   1\n",
      "Unique UMI counts for UMI length 5:\n",
      "              barcode   gene  unique_UMI_count_5\n",
      "0  AAACCAAAGGTGACGA-1  AAGAB                   1\n",
      "1  AAACCAAAGGTGACGA-1   AAK1                  15\n",
      "2  AAACCAAAGGTGACGA-1  AAMDC                   1\n",
      "3  AAACCAAAGGTGACGA-1   AAMP                   2\n",
      "4  AAACCAAAGGTGACGA-1   AAR2                   1\n",
      "Unique UMI counts for UMI length 6:\n",
      "              barcode   gene  unique_UMI_count_6\n",
      "0  AAACCAAAGGTGACGA-1  AAGAB                   1\n",
      "1  AAACCAAAGGTGACGA-1   AAK1                  15\n",
      "2  AAACCAAAGGTGACGA-1  AAMDC                   1\n",
      "3  AAACCAAAGGTGACGA-1   AAMP                   2\n",
      "4  AAACCAAAGGTGACGA-1   AAR2                   1\n",
      "Unique UMI counts for UMI length 7:\n",
      "              barcode   gene  unique_UMI_count_7\n",
      "0  AAACCAAAGGTGACGA-1  AAGAB                   1\n",
      "1  AAACCAAAGGTGACGA-1   AAK1                  15\n",
      "2  AAACCAAAGGTGACGA-1  AAMDC                   1\n",
      "3  AAACCAAAGGTGACGA-1   AAMP                   2\n",
      "4  AAACCAAAGGTGACGA-1   AAR2                   1\n",
      "Unique UMI counts for UMI length 8:\n",
      "              barcode   gene  unique_UMI_count_8\n",
      "0  AAACCAAAGGTGACGA-1  AAGAB                   1\n",
      "1  AAACCAAAGGTGACGA-1   AAK1                  15\n",
      "2  AAACCAAAGGTGACGA-1  AAMDC                   1\n",
      "3  AAACCAAAGGTGACGA-1   AAMP                   2\n",
      "4  AAACCAAAGGTGACGA-1   AAR2                   1\n",
      "Unique UMI counts for UMI length 9:\n",
      "              barcode   gene  unique_UMI_count_9\n",
      "0  AAACCAAAGGTGACGA-1  AAGAB                   1\n",
      "1  AAACCAAAGGTGACGA-1   AAK1                  15\n",
      "2  AAACCAAAGGTGACGA-1  AAMDC                   1\n",
      "3  AAACCAAAGGTGACGA-1   AAMP                   2\n",
      "4  AAACCAAAGGTGACGA-1   AAR2                   1\n",
      "Unique UMI counts for UMI length 10:\n",
      "              barcode   gene  unique_UMI_count_10\n",
      "0  AAACCAAAGGTGACGA-1  AAGAB                    1\n",
      "1  AAACCAAAGGTGACGA-1   AAK1                   16\n",
      "2  AAACCAAAGGTGACGA-1  AAMDC                    1\n",
      "3  AAACCAAAGGTGACGA-1   AAMP                    2\n",
      "4  AAACCAAAGGTGACGA-1   AAR2                    1\n",
      "Unique UMI counts for UMI length 11:\n",
      "              barcode   gene  unique_UMI_count_11\n",
      "0  AAACCAAAGGTGACGA-1  AAGAB                    1\n",
      "1  AAACCAAAGGTGACGA-1   AAK1                   16\n",
      "2  AAACCAAAGGTGACGA-1  AAMDC                    1\n",
      "3  AAACCAAAGGTGACGA-1   AAMP                    2\n",
      "4  AAACCAAAGGTGACGA-1   AAR2                    1\n",
      "Unique UMI counts for UMI length 12:\n",
      "              barcode   gene  unique_UMI_count_12\n",
      "0  AAACCAAAGGTGACGA-1  AAGAB                    1\n",
      "1  AAACCAAAGGTGACGA-1   AAK1                   16\n",
      "2  AAACCAAAGGTGACGA-1  AAMDC                    1\n",
      "3  AAACCAAAGGTGACGA-1   AAMP                    2\n",
      "4  AAACCAAAGGTGACGA-1   AAR2                    1\n",
      "Final merged table:\n",
      "              barcode   gene  unique_UMI_count_1  unique_UMI_count_2  \\\n",
      "0  AAACCAAAGGTGACGA-1  AAGAB                   1                   1   \n",
      "1  AAACCAAAGGTGACGA-1   AAK1                   4                  10   \n",
      "2  AAACCAAAGGTGACGA-1  AAMDC                   1                   1   \n",
      "3  AAACCAAAGGTGACGA-1   AAMP                   1                   1   \n",
      "4  AAACCAAAGGTGACGA-1   AAR2                   1                   1   \n",
      "\n",
      "   unique_UMI_count_3  unique_UMI_count_4  unique_UMI_count_5  \\\n",
      "0                   1                   1                   1   \n",
      "1                  15                  15                  15   \n",
      "2                   1                   1                   1   \n",
      "3                   2                   2                   2   \n",
      "4                   1                   1                   1   \n",
      "\n",
      "   unique_UMI_count_6  unique_UMI_count_7  unique_UMI_count_8  \\\n",
      "0                   1                   1                   1   \n",
      "1                  15                  15                  15   \n",
      "2                   1                   1                   1   \n",
      "3                   2                   2                   2   \n",
      "4                   1                   1                   1   \n",
      "\n",
      "   unique_UMI_count_9  unique_UMI_count_10  unique_UMI_count_11  \\\n",
      "0                   1                    1                    1   \n",
      "1                  15                   16                   16   \n",
      "2                   1                    1                    1   \n",
      "3                   2                    2                    2   \n",
      "4                   1                    1                    1   \n",
      "\n",
      "   unique_UMI_count_12  \n",
      "0                    1  \n",
      "1                   16  \n",
      "2                    1  \n",
      "3                    2  \n",
      "4                    1  \n"
     ]
    }
   ],
   "source": [
    "import pysam\n",
    "import pandas as pd\n",
    "\n",
    "# 1) INPUT: Path to the filtered BAM file (choose one dataset)\n",
    "# filtered_bam_path = '/data/dagyeman/cellranger/bam_file_analysis/1k_PBMCs/filtered_1k_PBMCS_bam.bam'   # BAM file for 1k dataset\n",
    "# filtered_bam_path = '/data/dagyeman/cellranger/bam_file_analysis/10k_PBMCs/filtered_10k_PBMCS_bam.bam' # BAM file for 10k dataset\n",
    "# filtered_bam_path = '/data/dagyeman/cellranger/bam_file_analysis/500_PBMCs/filtered_500_PBMCS_bam.bam'    # BAM file for 500 dataset\n",
    "filtered_bam_path = '/data/dagyeman/cellranger/bam_file_analysis/5k_PBMCs/filtered_5k_PBMCS_bam.bam'    # BAM file for 5k dataset\n",
    "\n",
    "# 2) data: list to hold extracted (barcode, gene, UMI) triplets\n",
    "data = []\n",
    "\n",
    "# 3) EXTRACT: Read BAM file and pull out barcode, gene, and UMI tags\n",
    "with pysam.AlignmentFile(filtered_bam_path, \"rb\") as bam_file:\n",
    "    for read in bam_file:\n",
    "        if read.has_tag('CB') and read.has_tag('GN') and read.has_tag('UB'):\n",
    "            barcode = read.get_tag('CB')  # string: cell barcode\n",
    "            gene = read.get_tag('GN')     # string: gene name\n",
    "            umi = read.get_tag('UB')      # string: unique molecular identifier\n",
    "            data.append([barcode, gene, umi])\n",
    "\n",
    "# 4) df: pandas DataFrame containing all reads with columns (barcode, gene, UMI)\n",
    "df = pd.DataFrame(data, columns=['barcode', 'gene', 'UMI'])\n",
    "print(\"First few raw rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# 5) CLEAN: Remove any rows where UMI contains ambiguous base 'N'\n",
    "df = df[~df['UMI'].str.contains('N')]\n",
    "\n",
    "# 6) deduplicated_df: DataFrame containing only unique (barcode, gene, UMI) combinations\n",
    "#    This is the deduplicated set of observed UMIs before truncating\n",
    "deduplicated_df = df.drop_duplicates(subset=['barcode', 'gene', 'UMI']).reset_index(drop=True)\n",
    "print(\"First few deduplicated rows:\")\n",
    "print(deduplicated_df.head())\n",
    "\n",
    "# 7) LOOP: For UMI lengths k = 1 to 12, compute number of unique UMIs per (barcode, gene)\n",
    "for k in range(1, 13):\n",
    "    deduplicated_df[f'UMI_{k}'] = deduplicated_df['UMI'].str[:k]  # first k bases\n",
    "    grouped_df = (\n",
    "        deduplicated_df.groupby(['barcode', 'gene'])[f'UMI_{k}']\n",
    "                       .nunique()\n",
    "                       .reset_index()\n",
    "                       .rename(columns={f'UMI_{k}': f'unique_UMI_count_{k}'})\n",
    "    )\n",
    "    print(f\"Unique UMI counts for UMI length {k}:\")\n",
    "    print(grouped_df.head())\n",
    "\n",
    "# 8) final_df: merged table with unique UMI counts for all lengths 1–12\n",
    "final_df = (\n",
    "    deduplicated_df.groupby(['barcode', 'gene'])\n",
    "                   .agg({f'UMI_{k}': 'nunique' for k in range(1, 13)})\n",
    "                   .reset_index()\n",
    ")\n",
    "final_df.columns = ['barcode', 'gene'] + [f'unique_UMI_count_{k}' for k in range(1, 13)]\n",
    "print(\"Final merged table:\")\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Adata Objects: Naive Method - created from final_df dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 5709 × 31131\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import anndata as ad\n",
    "\n",
    "# Dictionary to store the AnnData objects for each UMI length\n",
    "adata_dict = {}\n",
    "\n",
    "# Loop over UMI lengths from 1 to 12\n",
    "for k in range(1, 13):\n",
    "    # Extract the relevant columns for the current UMI length\n",
    "    # Contains: barcode, gene, and the deduplicated count for UMI length k\n",
    "    adata_matrix = final_df[['barcode', 'gene', f'unique_UMI_count_{k}']]\n",
    "\n",
    "    # Pivot the DataFrame:\n",
    "    # - Rows = barcodes (cells)\n",
    "    # - Columns = genes\n",
    "    # - Values = deduplicated UMI counts for the current UMI length\n",
    "    matrix_df = adata_matrix.pivot(\n",
    "        index='barcode',\n",
    "        columns='gene',\n",
    "        values=f'unique_UMI_count_{k}'\n",
    "    ).fillna(0)\n",
    "\n",
    "    # Create an AnnData object from the counts matrix\n",
    "    adata = ad.AnnData(X=matrix_df.values)\n",
    "\n",
    "    # Assign observation names (rows) to the barcodes\n",
    "    adata.obs_names = matrix_df.index\n",
    "\n",
    "    # Assign variable names (columns) to the gene names\n",
    "    adata.var_names = matrix_df.columns\n",
    "\n",
    "    # Store the AnnData object in the dictionary with the UMI length as the key\n",
    "    adata_dict[k] = adata\n",
    "\n",
    "# Example: View the AnnData object for UMI length 1\n",
    "print(adata_dict[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving naive adata objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved AnnData object for UMI length 1 to adata_UMI_length_1.h5ad\n",
      "Saved AnnData object for UMI length 2 to adata_UMI_length_2.h5ad\n",
      "Saved AnnData object for UMI length 3 to adata_UMI_length_3.h5ad\n",
      "Saved AnnData object for UMI length 4 to adata_UMI_length_4.h5ad\n",
      "Saved AnnData object for UMI length 5 to adata_UMI_length_5.h5ad\n",
      "Saved AnnData object for UMI length 6 to adata_UMI_length_6.h5ad\n",
      "Saved AnnData object for UMI length 7 to adata_UMI_length_7.h5ad\n",
      "Saved AnnData object for UMI length 8 to adata_UMI_length_8.h5ad\n",
      "Saved AnnData object for UMI length 9 to adata_UMI_length_9.h5ad\n",
      "Saved AnnData object for UMI length 10 to adata_UMI_length_10.h5ad\n",
      "Saved AnnData object for UMI length 11 to adata_UMI_length_11.h5ad\n",
      "Saved AnnData object for UMI length 12 to adata_UMI_length_12.h5ad\n"
     ]
    }
   ],
   "source": [
    "dataset = \"5k_PBMCs\"\n",
    "\n",
    "# file = \"/data/dagyeman/cellranger/bam_file_analysis/1k_PBMCs/ub_objects/adata_matrices/\" # saving path for 1k dataset\n",
    "filepath = f\"/data/dagyeman/cellranger/bam_file_analysis/{dataset}/ub_objects/adata_matrices/\" # saving path for 10k dataset \n",
    "\n",
    "for k in range(1, 13):\n",
    "    # Save each AnnData object to a file\n",
    "    adata_dict[k].write_h5ad(f'{filepath}adata_UMI_length_{k}.h5ad')\n",
    "    print(f'Saved AnnData object for UMI length {k} to adata_UMI_length_{k}.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Adata Objects: Uniform Estimator "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating AnnData matrix for uniform estimator at length k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 5709 × 31131\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "from umi_utils import mom_estimator_unif\n",
    "\n",
    "dataset = \"5k_PBMCs\"  # Change this to \"1k_PBMCs\" or \"500_PBMCs\" as needed\n",
    "filepath = f\"/data/dagyeman/cellranger/bam_file_analysis/{dataset}/ub_objects\" #10k\n",
    "\n",
    "# Load naive AnnData counts (UMI lengths 1–12)\n",
    "adata_dict = {}\n",
    "for i in range(1, 13):\n",
    "    adata_dict[i] = sc.read_h5ad(f\"{filepath}/adata_matrices/adata_{i}.h5ad\")\n",
    "    \n",
    "\n",
    "# Build the predicted AnnData for a chosen UMI length k \n",
    "chosen_k = 6  # set this as needed\n",
    "\n",
    "adata = adata_dict[chosen_k]                 # naive counts AnnData for k\n",
    "\n",
    "# Dense matrix view of counts\n",
    "matrix = adata.X.toarray() if hasattr(adata.X, \"toarray\") else adata.X\n",
    "original_matrix = matrix.copy()              # keep a copy if you want to compare later\n",
    "\n",
    "# Predict counts with your estimator\n",
    "predicted_matrix = mom_estimator_unif(matrix, 4**chosen_k)\n",
    "# AnnData with predicted counts (cells x genes align with the naive object)\n",
    "predicted_adata = ad.AnnData(X=predicted_matrix)\n",
    "predicted_adata.obs_names = adata.obs_names\n",
    "predicted_adata.var_names = adata.var_names\n",
    "\n",
    "# Example check\n",
    "print(predicted_adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving adata matrices for unif estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /data/dagyeman/cellranger/bam_file_analysis/5k_PBMCs/ub_objects/col_aware_unif_matrices/adata_1.h5ad\n",
      "Saved: /data/dagyeman/cellranger/bam_file_analysis/5k_PBMCs/ub_objects/col_aware_unif_matrices/adata_2.h5ad\n",
      "Saved: /data/dagyeman/cellranger/bam_file_analysis/5k_PBMCs/ub_objects/col_aware_unif_matrices/adata_3.h5ad\n",
      "Saved: /data/dagyeman/cellranger/bam_file_analysis/5k_PBMCs/ub_objects/col_aware_unif_matrices/adata_4.h5ad\n",
      "Saved: /data/dagyeman/cellranger/bam_file_analysis/5k_PBMCs/ub_objects/col_aware_unif_matrices/adata_5.h5ad\n",
      "Saved: /data/dagyeman/cellranger/bam_file_analysis/5k_PBMCs/ub_objects/col_aware_unif_matrices/adata_6.h5ad\n",
      "Saved: /data/dagyeman/cellranger/bam_file_analysis/5k_PBMCs/ub_objects/col_aware_unif_matrices/adata_7.h5ad\n",
      "Saved: /data/dagyeman/cellranger/bam_file_analysis/5k_PBMCs/ub_objects/col_aware_unif_matrices/adata_8.h5ad\n",
      "Saved: /data/dagyeman/cellranger/bam_file_analysis/5k_PBMCs/ub_objects/col_aware_unif_matrices/adata_9.h5ad\n",
      "Saved: /data/dagyeman/cellranger/bam_file_analysis/5k_PBMCs/ub_objects/col_aware_unif_matrices/adata_10.h5ad\n",
      "Saved: /data/dagyeman/cellranger/bam_file_analysis/5k_PBMCs/ub_objects/col_aware_unif_matrices/adata_11.h5ad\n",
      "Saved: /data/dagyeman/cellranger/bam_file_analysis/5k_PBMCs/ub_objects/col_aware_unif_matrices/adata_12.h5ad\n",
      "AnnData object with n_obs × n_vars = 5709 × 31131\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import os\n",
    "from umi_utils import mom_estimator_unif\n",
    "\n",
    "dataset = \"5k_PBMCs\"  # Change this to \"1k_PBMCs\" or \"500_PBMCs\" as needed\n",
    "filepath = f\"/data/dagyeman/cellranger/bam_file_analysis/{dataset}/ub_objects\"   # 10k\n",
    "\n",
    "# Load naive AnnData counts (UMI lengths 1–12)\n",
    "adata_dict = {}\n",
    "for i in range(1, 13):\n",
    "    adata_dict[i] = sc.read_h5ad(f\"{filepath}/adata_matrices/adata_{i}.h5ad\")\n",
    "\n",
    "# Output directory for uniform-estimator predictions\n",
    "save_dir = f\"{filepath}/col_aware_unif_matrices\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Build and save predicted AnnData for each UMI length k\n",
    "for k in range(1, 13):\n",
    "    adata = adata_dict[k]\n",
    "    matrix = adata.X.toarray() if hasattr(adata.X, \"toarray\") else adata.X\n",
    "\n",
    "    predicted_matrix = mom_estimator_unif(matrix, 4**k)\n",
    "\n",
    "    predicted_adata = ad.AnnData(X=predicted_matrix)\n",
    "    predicted_adata.obs_names = adata.obs_names\n",
    "    predicted_adata.var_names = adata.var_names\n",
    "\n",
    "    out_path = os.path.join(save_dir, f\"adata_{k}.h5ad\")\n",
    "    predicted_adata.write_h5ad(out_path)\n",
    "    print(f\"Saved: {out_path}\")\n",
    "\n",
    "# Example check\n",
    "print(sc.read_h5ad(os.path.join(save_dir, \"adata_6.h5ad\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Adata Objects: Non-uniform Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating UMI probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## nucleotide probabilities\n",
    "nt_probs = {'A': 0.23, 'C': 0.24, 'G': 0.21, 'T': 0.32}\n",
    "\n",
    "def generate_umis_and_probs(max_len=12):\n",
    "    umi_dfs = {}\n",
    "    for length in range(1, max_len + 1):\n",
    "        \n",
    "        # generate all UMIs for this length\n",
    "        umis = [''.join(p) for p in itertools.product(nt_probs.keys(), repeat=length)]\n",
    "        \n",
    "        # compute probabilities by multiplying nucleotide probs\n",
    "        probs = [np.prod([nt_probs[base] for base in umi]) for umi in umis]\n",
    "        # Store in a DataFrame\n",
    "        df = pd.DataFrame({'UMI': umis, 'Probability': probs})\n",
    "        umi_dfs[length] = df\n",
    "    return umi_dfs\n",
    "\n",
    "# Example usage\n",
    "umis_dict = generate_umis_and_probs(12)\n",
    "\n",
    "## view UMIs of length 4\n",
    "print(umis_dict[4].head(10))\n",
    "print(\"Total UMIs for length 4:\", len(umis_dict[4]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating AnnData matrix for non-uniform estimator at length k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found n_max = 8192 where f(n_max)= 1021.2942848258443 > 1020\n",
      "f(n_max/2)= 986.0597505200279 < 1020\n",
      "Generating estimator lookup table for Y_max = 1020 using n_max = 8192...\n",
      "Estimator generated successfully.\n",
      "AnnData object with n_obs × n_vars = 5709 × 31131\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "from umi_utils import generate_nonunif_estimator\n",
    "dataset = \"5k_PBMCs\"  # Change this to \"1k_PBMCs\" or \"500_PBMCs\" as needed\n",
    "# filepath = \"/data/dagyeman/cellranger/bam_file_analysis/1k_PBMCs/ub_objects\" #1k\n",
    "filepath = f\"/data/dagyeman/cellranger/bam_file_analysis/{dataset}/ub_objects\" #10k\n",
    "\n",
    "# Load naive AnnData counts (UMI lengths 1–12)\n",
    "adata_dict = {}\n",
    "for i in range(1, 13):\n",
    "    adata_dict[i] = sc.read_h5ad(f\"{filepath}/adata_matrices/adata_{i}.h5ad\")\n",
    "\n",
    "# Load non-uniform UMI probability distributions (UMI lengths 1–12)\n",
    "umi_prob_dict = {}\n",
    "for i in range(1, 13):\n",
    "    umi_prob_dict[i] = pd.read_csv(f\"/data/dagyeman/cellranger/bam_file_analysis/data/umi_probs/umi_probs_{i}.csv\")\n",
    "\n",
    "# Build the predicted AnnData for a chosen UMI length k\n",
    "chosen_k = 5  # set this as needed\n",
    "\n",
    "adata = adata_dict[chosen_k]                 # naive counts AnnData for k\n",
    "umi_probs = umi_prob_dict[chosen_k]['prob']  # non-uniform probs for k\n",
    "\n",
    "# Dense matrix view of counts\n",
    "matrix = adata.X.toarray() if hasattr(adata.X, \"toarray\") else adata.X\n",
    "original_matrix = matrix.copy()              # keep a copy if you want to compare later\n",
    "\n",
    "\n",
    "# Build the estimator \n",
    "Y_max = int(min(original_matrix.max(), 4**chosen_k))\n",
    "estimator = generate_nonunif_estimator(umi_probs.values, chosen_k, Y_max, verbose=True)\n",
    "\n",
    "# Predict counts with your estimator\n",
    "predicted_matrix = estimator(original_matrix)\n",
    "\n",
    "# AnnData with predicted counts (cells x genes align with the naive object)\n",
    "predicted_adata = ad.AnnData(X=predicted_matrix)\n",
    "predicted_adata.obs_names = adata.obs_names\n",
    "predicted_adata.var_names = adata.var_names\n",
    "\n",
    "# Example check\n",
    "print(predicted_adata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving collision_aware matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5709, 31131)\n",
      "Saved: /data/dagyeman/cellranger/bam_file_analysis/5k_PBMCs/ub_objects/col_aware_nunif_matrices/adata_1.h5ad\n",
      "Saved: /data/dagyeman/cellranger/bam_file_analysis/5k_PBMCs/ub_objects/col_aware_nunif_matrices/adata_2.h5ad\n",
      "Saved: /data/dagyeman/cellranger/bam_file_analysis/5k_PBMCs/ub_objects/col_aware_nunif_matrices/adata_3.h5ad\n",
      "Saved: /data/dagyeman/cellranger/bam_file_analysis/5k_PBMCs/ub_objects/col_aware_nunif_matrices/adata_4.h5ad\n",
      "Saved: /data/dagyeman/cellranger/bam_file_analysis/5k_PBMCs/ub_objects/col_aware_nunif_matrices/adata_5.h5ad\n",
      "Saved: /data/dagyeman/cellranger/bam_file_analysis/5k_PBMCs/ub_objects/col_aware_nunif_matrices/adata_6.h5ad\n",
      "Saved: /data/dagyeman/cellranger/bam_file_analysis/5k_PBMCs/ub_objects/col_aware_nunif_matrices/adata_7.h5ad\n",
      "Saved: /data/dagyeman/cellranger/bam_file_analysis/5k_PBMCs/ub_objects/col_aware_nunif_matrices/adata_8.h5ad\n",
      "Saved: /data/dagyeman/cellranger/bam_file_analysis/5k_PBMCs/ub_objects/col_aware_nunif_matrices/adata_9.h5ad\n",
      "Saved: /data/dagyeman/cellranger/bam_file_analysis/5k_PBMCs/ub_objects/col_aware_nunif_matrices/adata_10.h5ad\n",
      "Saved: /data/dagyeman/cellranger/bam_file_analysis/5k_PBMCs/ub_objects/col_aware_nunif_matrices/adata_11.h5ad\n",
      "Saved: /data/dagyeman/cellranger/bam_file_analysis/5k_PBMCs/ub_objects/col_aware_nunif_matrices/adata_12.h5ad\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import os\n",
    "from umi_utils import generate_nonunif_estimator  \n",
    "\n",
    "dataset = \"5k_PBMCs\"  # Change this to \"1k_PBMCs\" or \"500_PBMCs\" as needed\n",
    "filepath = f\"/data/dagyeman/cellranger/bam_file_analysis/{dataset}/ub_objects\"   # 10k\n",
    "\n",
    "# Load naive AnnData counts (UMI lengths 1–12)\n",
    "adata_dict = {}\n",
    "for i in range(1, 13):\n",
    "    adata_dict[i] = sc.read_h5ad(f\"{filepath}/adata_matrices/adata_{i}.h5ad\")\n",
    "    \n",
    "print(adata_dict[1].shape)\n",
    "\n",
    "# Load non-uniform UMI probability distributions (UMI lengths 1–12)\n",
    "umi_prob_dict = {}\n",
    "for i in range(1, 13):\n",
    "    umi_prob_dict[i] = pd.read_csv(f\"/data/dagyeman/cellranger/bam_file_analysis/data/umi_probs/umi_probs_{i}.csv\")\n",
    "\n",
    "# Output directory for non-uniform estimator predictions\n",
    "save_dir = f\"{filepath}/col_aware_nunif_matrices\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for k in range(1, 13):\n",
    "    adata = adata_dict[k]\n",
    "    umi_probs = umi_prob_dict[k]['prob']\n",
    "\n",
    "    # Get the counts matrix\n",
    "    matrix = adata.X.toarray() if hasattr(adata.X, \"toarray\") else adata.X\n",
    "\n",
    "    # Compute Y_max for this matrix\n",
    "    Y_max = int(min(matrix.max(), 4**k))\n",
    "\n",
    "    # Build the estimator for this k\n",
    "    estimator = generate_nonunif_estimator(umi_probs.values, k, Y_max, verbose=False)\n",
    "\n",
    "    # Apply it to the matrix\n",
    "    predicted_matrix = estimator(matrix.astype(int))\n",
    "\n",
    "    # Wrap back into AnnData\n",
    "    predicted_adata = ad.AnnData(X=predicted_matrix)\n",
    "    predicted_adata.obs_names = adata.obs_names\n",
    "    predicted_adata.var_names = adata.var_names\n",
    "\n",
    "    # Save\n",
    "    out_path = os.path.join(save_dir, f\"adata_{k}.h5ad\")\n",
    "    predicted_adata.write_h5ad(out_path)\n",
    "    print(f\"Saved: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
